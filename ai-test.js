import 'dotenv/config';
import AIService from './services/ai.service.js';

// Importar mock de UploadService si es necesario para testing
// import UploadService from '../services/upload.service.js';
// jest.mock('../services/upload.service.js');

/**
 * Test para AIService con OpenAI
 * Este archivo contiene pruebas para todas las funciones de AIService:
 * - generateCoverImage
 * - sendMessage
 * - solveModelInfo
 * - solveProviderUrl
 * - adjustContent
 * - estimateTokens
 */

// ConfiguraciÃ³n de entorno para los tests
async function setupTest() {
  console.log('ğŸ§ª Configurando entorno de pruebas...');

  // Verificar que las variables de entorno necesarias estÃ©n definidas
  const requiredEnvVars = [
    'OPENAI_API_KEY'
  ];

  const missingVars = requiredEnvVars.filter(varName => !process.env[varName]);
  if (missingVars.length > 0) {
    console.warn(`âš ï¸ Faltan las siguientes variables de entorno: ${missingVars.join(', ')}`);
    console.warn('Los tests que requieran estas variables pueden fallar');
  }
}

// Tests para generateCoverImage
async function testGenerateCoverImage() {
  console.log('\nğŸ§ª TEST: generateCoverImage');

  try {
    const prompt = 'Un hermoso paisaje de montaÃ±as al atardecer con un lago reflectante en primer plano';
    const options = {
      size: '512x512',
      model: 'dall-e-2',
      n: 1
    };

    console.log('ğŸ“ Datos de entrada:');
    console.log('- Prompt:', prompt);
    console.log('- Opciones:', options);

    const attachment = await AIService.generateCoverImage(prompt, options);

    console.log('âœ… Test EXITOSO de generateCoverImage');
    console.log('ğŸ“¦ Resultado (Attachment):', attachment);
    return attachment;
  } catch (error) {
    console.error('âŒ Test FALLIDO de generateCoverImage:', error.message);
    throw error;
  }
}

// Tests para sendMessage (OpenAI con GPT-4.1 Nano)
async function testSendMessageOpenAI() {
  console.log('\nğŸ§ª TEST: sendMessage (OpenAI con GPT-4.1 Nano)');

  try {
    const data = {
      model: 'gpt-4.1-nano',
      system: 'Eres un asistente Ãºtil y amigable.',
      prompt: 'Â¿Puedes explicarme brevemente quÃ© es la inteligencia artificial?',
      temperature: 0.7,
      max_tokens: 500,
      stream: false
    };

    console.log('ğŸ“ Datos de entrada:');
    console.log(JSON.stringify(data, null, 2));

    const response = await AIService.sendMessage(data);

    console.log('âœ… Test EXITOSO de sendMessage (OpenAI con GPT-4.1 Nano)');
    console.log('ğŸ“¦ Estructura de respuesta:');
    console.log(JSON.stringify(response, null, 2));
    return response;
  } catch (error) {
    console.error('âŒ Test FALLIDO de sendMessage (OpenAI):', error.message);
    throw error;
  }
}

// Test para sendMessage con tools/function calling (GPT-4.1 Nano)
async function testSendMessageWithTools() {
  console.log('\nğŸ§ª TEST: sendMessage con herramientas (function calling) usando GPT-4.1 Nano');

  try {
    const tools = [
      {
        type: "function",
        function: {
          name: "get_weather",
          description: "Obtiene el clima actual para una ubicaciÃ³n",
          parameters: {
            type: "object",
            properties: {
              location: {
                type: "string",
                description: "La ciudad y estado, por ejemplo: 'San Francisco, CA'"
              },
              unit: {
                type: "string",
                enum: ["celsius", "fahrenheit"],
                description: "Unidad de temperatura"
              }
            },
            required: ["location"]
          }
        }
      }
    ];

    const data = {
      model: 'gpt-4.1-nano',
      system: 'Eres un asistente Ãºtil especializado en informaciÃ³n meteorolÃ³gica.',
      prompt: 'Â¿CuÃ¡l es el clima hoy en Madrid?',
      temperature: 0.7,
      tools: tools,
      toolChoice: "auto",
      stream: false
    };

    console.log('ğŸ“ Datos de entrada (con tools):');
    console.log(JSON.stringify(data, null, 2));

    const response = await AIService.sendMessage(data);

    console.log('âœ… Test EXITOSO de sendMessage con tools');
    console.log('ğŸ“¦ Estructura de respuesta con function calling:');
    console.log(JSON.stringify(response, null, 2));
    return response;
  } catch (error) {
    console.error('âŒ Test FALLIDO de sendMessage con tools:', error.message);
    throw error;
  }
}

// Test para sendMessage con JSON mode (GPT-4.1 Nano)
async function testSendMessageWithJsonMode() {
  console.log('\nğŸ§ª TEST: sendMessage con JSON mode usando GPT-4.1 Nano');

  try {
    const data = {
      model: 'gpt-4.1-nano',
      system: 'Eres un asistente que responde exclusivamente en formato JSON.',
      prompt: 'Dame informaciÃ³n sobre 3 paÃ­ses de Europa, incluyendo su capital, poblaciÃ³n y idioma oficial. Responde en JSON.',
      temperature: 0.7,
      responseFormat: { type: "json_object" },
      stream: false
    };

    console.log('ğŸ“ Datos de entrada (con responseFormat):');
    console.log(JSON.stringify(data, null, 2));

    const response = await AIService.sendMessage(data);

    console.log('âœ… Test EXITOSO de sendMessage con JSON mode');
    console.log('ğŸ“¦ Estructura de respuesta en JSON mode:');
    console.log(JSON.stringify(response, null, 2));
    return response;
  } catch (error) {
    console.error('âŒ Test FALLIDO de sendMessage con JSON mode:', error.message);
    throw error;
  }
}

// Test para sendMessage con streaming (GPT-4.1 Nano)
async function testSendMessageStreaming() {
  console.log('\nğŸ§ª TEST: sendMessage con streaming usando GPT-4.1 Nano');

  try {
    const data = {
      model: 'gpt-4.1-nano',
      system: 'Eres un asistente Ãºtil y conciso.',
      prompt: 'Cuenta una historia corta sobre un robot.',
      temperature: 0.7,
      stream: true
    };

    console.log('ğŸ“ Datos de entrada (streaming):');
    console.log(JSON.stringify(data, null, 2));

    const stream = await AIService.sendMessage(data);

    console.log('âœ… Test EXITOSO de sendMessage con streaming');
    console.log('ğŸ“¦ Objeto stream recibido:', typeof stream);
    console.log('Para consumir el stream, usarÃ­as algo como:');
    console.log(`
    stream.on('data', chunk => {
      const lines = chunk.toString().split('\\n').filter(line => line.trim() !== '');
      for (const line of lines) {
        if (line.startsWith('data: ')) {
          const data = line.substring(6);
          if (data === '[DONE]') {
            console.log('Stream completado');
          } else {
            try {
              const parsed = JSON.parse(data);
              console.log(parsed.choices[0]?.delta?.content || '');
            } catch (e) {
              console.error('Error parseando chunk:', e);
            }
          }
        }
      }
    });
    `);

    return stream;
  } catch (error) {
    console.error('âŒ Test FALLIDO de sendMessage con streaming:', error.message);
    throw error;
  }
}

// No incluimos tests para otros proveedores ya que nos enfocaremos solo en OpenAI con el modelo mÃ¡s econÃ³mico

// Tests para mÃ©todos internos
async function testInternalMethods() {
  console.log('\nğŸ§ª TEST: MÃ©todos internos de AIService');

  try {
    // Test para solveModelInfo
    console.log('\n1ï¸âƒ£ TEST: solveModelInfo');
    const modelInfo = AIService.solveModelInfo('gpt-4');
    console.log('ğŸ“¦ Resultado de solveModelInfo:');
    console.log(JSON.stringify(modelInfo, null, 2));

    // Test para solveProviderUrl
    console.log('\n2ï¸âƒ£ TEST: solveProviderUrl');
    const url = AIService.solveProviderUrl('openai');
    console.log('ğŸ“¦ Resultado de solveProviderUrl:', url);

    // Test para estimateTokens
    console.log('\n3ï¸âƒ£ TEST: estimateTokens');
    const messages = [
      { role: 'system', content: 'Eres un asistente Ãºtil.' },
      { role: 'user', content: 'Hola, Â¿cÃ³mo estÃ¡s?' },
      { role: 'assistant', content: 'Estoy bien, Â¿en quÃ© puedo ayudarte?' },
      { role: 'user', content: 'CuÃ©ntame sobre la inteligencia artificial.' }
    ];
    const tokenCount = AIService.estimateTokens(messages);
    console.log('ğŸ“¦ Resultado de estimateTokens para los mensajes:', tokenCount);

    // Test para adjustContent
    console.log('\n4ï¸âƒ£ TEST: adjustContent');
    const system = 'Eres un asistente muy Ãºtil y amigable que proporciona informaciÃ³n detallada.';
    const history = [
      { role: 'user', content: 'Hola, Â¿me puedes ayudar con un proyecto?' },
      { role: 'assistant', content: 'Claro, estarÃ© encantado de ayudarte. Â¿De quÃ© trata tu proyecto?' },
      { role: 'user', content: 'Es sobre inteligencia artificial' },
      { role: 'assistant', content: 'Excelente tema. La inteligencia artificial es un campo fascinante. Â¿QuÃ© aspecto especÃ­fico quieres explorar?' }
    ];
    const prompt = 'Necesito entender cÃ³mo funcionan los transformers en el procesamiento de lenguaje natural.';
    const contextWindow = 2000; // Valor pequeÃ±o para forzar ajustes

    const adjusted = AIService.adjustContent(system, [...history], prompt, contextWindow);
    console.log('ğŸ“¦ Resultado de adjustContent:');
    console.log('- System ajustado (longitud):', adjusted.system.length);
    console.log('- History ajustada (longitud):', adjusted.history.length);
    console.log('- Prompt ajustado (longitud):', adjusted.prompt.length);

    console.log('âœ… Test EXITOSO de mÃ©todos internos');
    return { modelInfo, url, tokenCount, adjusted };
  } catch (error) {
    console.error('âŒ Test FALLIDO de mÃ©todos internos:', error.message);
    throw error;
  }
}

// FunciÃ³n principal para ejecutar todos los tests
async function runAllTests() {
  console.log('ğŸš€ INICIANDO TESTS DE AIService (SÃ³lo OpenAI con GPT-4.1 Nano)');

  try {
    await setupTest();

    // Tests principales
    // await testGenerateCoverImage();
    await testSendMessageOpenAI();
    await testSendMessageWithTools();
    await testSendMessageWithJsonMode();
    await testSendMessageStreaming();

    // Tests de mÃ©todos internos
    await testInternalMethods();

    console.log('\nâœ…âœ…âœ… TODOS LOS TESTS COMPLETADOS CON Ã‰XITO âœ…âœ…âœ…');
  } catch (error) {
    console.error('\nâŒâŒâŒ FALLOS EN LOS TESTS âŒâŒâŒ');
    console.error('Error general:', error);
  }
}

// Ejecutar todos los tests
runAllTests();
