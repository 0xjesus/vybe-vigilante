import 'dotenv/config';
import AIService from './services/ai.service.js';

// Importar mock de UploadService si es necesario para testing
// import UploadService from '../services/upload.service.js';
// jest.mock('../services/upload.service.js');

/**
 * Test para AIService con OpenAI
 * Este archivo contiene pruebas para todas las funciones de AIService:
 * - generateCoverImage
 * - sendMessage
 * - solveModelInfo
 * - solveProviderUrl
 * - adjustContent
 * - estimateTokens
 */

// Configuraci√≥n de entorno para los tests
async function setupTest() {
  console.log('üß™ Configurando entorno de pruebas...');

  // Verificar que las variables de entorno necesarias est√©n definidas
  const requiredEnvVars = [
    'OPENAI_API_KEY'
  ];

  const missingVars = requiredEnvVars.filter(varName => !process.env[varName]);
  if (missingVars.length > 0) {
    console.warn(`‚ö†Ô∏è Faltan las siguientes variables de entorno: ${missingVars.join(', ')}`);
    console.warn('Los tests que requieran estas variables pueden fallar');
  }
}

// Tests para generateCoverImage
async function testGenerateCoverImage() {
  console.log('\nüß™ TEST: generateCoverImage');

  try {
    const prompt = 'Un hermoso paisaje de monta√±as al atardecer con un lago reflectante en primer plano';
    const options = {
      size: '512x512',
      model: 'dall-e-2',
      n: 1
    };

    console.log('üìù Datos de entrada:');
    console.log('- Prompt:', prompt);
    console.log('- Opciones:', options);

    const attachment = await AIService.generateCoverImage(prompt, options);

    console.log('‚úÖ Test EXITOSO de generateCoverImage');
    console.log('üì¶ Resultado (Attachment):', attachment);
    return attachment;
  } catch (error) {
    console.error('‚ùå Test FALLIDO de generateCoverImage:', error.message);
    throw error;
  }
}

// Tests para sendMessage (OpenAI con GPT-4.1 Nano)
async function testSendMessageOpenAI() {
  console.log('\nüß™ TEST: sendMessage (OpenAI con GPT-4.1 Nano)');

  try {
    const data = {
      model: 'gpt-4.1-nano',
      system: 'Eres un asistente √∫til y amigable.',
      prompt: '¬øPuedes explicarme brevemente qu√© es la inteligencia artificial?',
      temperature: 0.7,
      max_tokens: 500,
      stream: false
    };

    console.log('üìù Datos de entrada:');
    console.log(JSON.stringify(data, null, 2));

    const response = await AIService.sendMessage(data);

    console.log('‚úÖ Test EXITOSO de sendMessage (OpenAI con GPT-4.1 Nano)');
    console.log('üì¶ Estructura de respuesta:');
    console.log(JSON.stringify(response, null, 2));
    return response;
  } catch (error) {
    console.error('‚ùå Test FALLIDO de sendMessage (OpenAI):', error.message);
    throw error;
  }
}

// Test para sendMessage con tools/function calling (GPT-4.1 Nano)
async function testSendMessageWithTools() {
  console.log('\nüß™ TEST: sendMessage con herramientas (function calling) usando GPT-4.1 Nano');

  try {
    const tools = [
      {
        type: "function",
        function: {
          name: "get_weather",
          description: "Obtiene el clima actual para una ubicaci√≥n",
          parameters: {
            type: "object",
            properties: {
              location: {
                type: "string",
                description: "La ciudad y estado, por ejemplo: 'San Francisco, CA'"
              },
              unit: {
                type: "string",
                enum: ["celsius", "fahrenheit"],
                description: "Unidad de temperatura"
              }
            },
            required: ["location"]
          }
        }
      }
    ];

    const data = {
      model: 'gpt-4.1-nano',
      system: 'Eres un asistente √∫til especializado en informaci√≥n meteorol√≥gica.',
      prompt: '¬øCu√°l es el clima hoy en Madrid?',
      temperature: 0.7,
      tools: tools,
      toolChoice: "auto",
      stream: false
    };

    console.log('üìù Datos de entrada (con tools):');
    console.log(JSON.stringify(data, null, 2));

    const response = await AIService.sendMessage(data);

    console.log('‚úÖ Test EXITOSO de sendMessage con tools');
    console.log('üì¶ Estructura de respuesta con function calling:');
    console.log(JSON.stringify(response, null, 2));
    return response;
  } catch (error) {
    console.error('‚ùå Test FALLIDO de sendMessage con tools:', error.message);
    throw error;
  }
}

// Test para sendMessage con JSON mode (GPT-4.1 Nano)
async function testSendMessageWithJsonMode() {
  console.log('\nüß™ TEST: sendMessage con JSON mode usando GPT-4.1 Nano');

  try {
    const data = {
      model: 'gpt-4.1-nano',
      system: 'Eres un asistente que responde exclusivamente en formato JSON.',
      prompt: 'Dame informaci√≥n sobre 3 pa√≠ses de Europa, incluyendo su capital, poblaci√≥n y idioma oficial. Responde en JSON.',
      temperature: 0.7,
      responseFormat: { type: "json_object" },
      stream: false
    };

    console.log('üìù Datos de entrada (con responseFormat):');
    console.log(JSON.stringify(data, null, 2));

    const response = await AIService.sendMessage(data);

    console.log('‚úÖ Test EXITOSO de sendMessage con JSON mode');
    console.log('üì¶ Estructura de respuesta en JSON mode:');
    console.log(JSON.stringify(response, null, 2));
    return response;
  } catch (error) {
    console.error('‚ùå Test FALLIDO de sendMessage con JSON mode:', error.message);
    throw error;
  }
}

// Test para sendMessage con streaming (GPT-4.1 Nano)
async function testSendMessageStreaming() {
  console.log('\nüß™ TEST: sendMessage con streaming usando GPT-4.1 Nano');

  try {
    const data = {
      model: 'gpt-4.1-nano',
      system: 'Eres un asistente √∫til y conciso.',
      prompt: 'Cuenta una historia corta sobre un robot.',
      temperature: 0.7,
      stream: true
    };

    console.log('üìù Datos de entrada (streaming):');
    console.log(JSON.stringify(data, null, 2));

    const stream = await AIService.sendMessage(data);

    console.log('‚úÖ Test EXITOSO de sendMessage con streaming');
    console.log('üì¶ Objeto stream recibido:', typeof stream);
    console.log('Para consumir el stream, usar√≠as algo como:');
    console.log(`
    stream.on('data', chunk => {
      const lines = chunk.toString().split('\\n').filter(line => line.trim() !== '');
      for (const line of lines) {
        if (line.startsWith('data: ')) {
          const data = line.substring(6);
          if (data === '[DONE]') {
            console.log('Stream completado');
          } else {
            try {
              const parsed = JSON.parse(data);
              console.log(parsed.choices[0]?.delta?.content || '');
            } catch (e) {
              console.error('Error parseando chunk:', e);
            }
          }
        }
      }
    });
    `);

    return stream;
  } catch (error) {
    console.error('‚ùå Test FALLIDO de sendMessage con streaming:', error.message);
    throw error;
  }
}

// No incluimos tests para otros proveedores ya que nos enfocaremos solo en OpenAI con el modelo m√°s econ√≥mico

// Tests para m√©todos internos
async function testInternalMethods() {
  console.log('\nüß™ TEST: M√©todos internos de AIService');

  try {
    // Test para solveModelInfo
    console.log('\n1Ô∏è‚É£ TEST: solveModelInfo');
    const modelInfo = AIService.solveModelInfo('gpt-4');
    console.log('üì¶ Resultado de solveModelInfo:');
    console.log(JSON.stringify(modelInfo, null, 2));

    // Test para solveProviderUrl
    console.log('\n2Ô∏è‚É£ TEST: solveProviderUrl');
    const url = AIService.solveProviderUrl('openai');
    console.log('üì¶ Resultado de solveProviderUrl:', url);

    // Test para estimateTokens
    console.log('\n3Ô∏è‚É£ TEST: estimateTokens');
    const messages = [
      { role: 'system', content: 'Eres un asistente √∫til.' },
      { role: 'user', content: 'Hola, ¬øc√≥mo est√°s?' },
      { role: 'assistant', content: 'Estoy bien, ¬øen qu√© puedo ayudarte?' },
      { role: 'user', content: 'Cu√©ntame sobre la inteligencia artificial.' }
    ];
    const tokenCount = AIService.estimateTokens(messages);
    console.log('üì¶ Resultado de estimateTokens para los mensajes:', tokenCount);

    // Test para adjustContent
    console.log('\n4Ô∏è‚É£ TEST: adjustContent');
    const system = 'Eres un asistente muy √∫til y amigable que proporciona informaci√≥n detallada.';
    const history = [
      { role: 'user', content: 'Hola, ¬øme puedes ayudar con un proyecto?' },
      { role: 'assistant', content: 'Claro, estar√© encantado de ayudarte. ¬øDe qu√© trata tu proyecto?' },
      { role: 'user', content: 'Es sobre inteligencia artificial' },
      { role: 'assistant', content: 'Excelente tema. La inteligencia artificial es un campo fascinante. ¬øQu√© aspecto espec√≠fico quieres explorar?' }
    ];
    const prompt = 'Necesito entender c√≥mo funcionan los transformers en el procesamiento de lenguaje natural.';
    const contextWindow = 2000; // Valor peque√±o para forzar ajustes

    const adjusted = AIService.adjustContent(system, [...history], prompt, contextWindow);
    console.log('üì¶ Resultado de adjustContent:');
    console.log('- System ajustado (longitud):', adjusted.system.length);
    console.log('- History ajustada (longitud):', adjusted.history.length);
    console.log('- Prompt ajustado (longitud):', adjusted.prompt.length);

    console.log('‚úÖ Test EXITOSO de m√©todos internos');
    return { modelInfo, url, tokenCount, adjusted };
  } catch (error) {
    console.error('‚ùå Test FALLIDO de m√©todos internos:', error.message);
    throw error;
  }
}

// Funci√≥n principal para ejecutar todos los tests
async function runAllTests() {
  console.log('üöÄ INICIANDO TESTS DE AIService (S√≥lo OpenAI con GPT-4.1 Nano)');

  try {
    await setupTest();

    // Tests principales
    // await testGenerateCoverImage();
    await testSendMessageOpenAI();
    await testSendMessageWithTools();
    await testSendMessageWithJsonMode();
    await testSendMessageStreaming();

    // Tests de m√©todos internos
    await testInternalMethods();

    console.log('\n‚úÖ‚úÖ‚úÖ TODOS LOS TESTS COMPLETADOS CON √âXITO ‚úÖ‚úÖ‚úÖ');
  } catch (error) {
    console.error('\n‚ùå‚ùå‚ùå FALLOS EN LOS TESTS ‚ùå‚ùå‚ùå');
    console.error('Error general:', error);
  }
}

// Ejecutar todos los tests
runAllTests();
